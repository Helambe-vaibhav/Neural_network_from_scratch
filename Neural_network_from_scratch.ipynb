{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "# import train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Display plots inline and change default figure size\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# np.random.seed(1) # set a seed so that the results are consistent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "data = pd.read_csv('Iris.csv')\n",
    "data.drop('Id',axis=1,inplace=True)\n",
    "# remove rows having Iris-virginica as species\n",
    "data = data[data.Species != 'Iris-virginica']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1]], dtype=int64)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop('Species',axis=1)\n",
    "Y = data['Species']\n",
    "Y = Y.replace('Iris-setosa',0)\n",
    "Y = Y.replace('Iris-versicolor',1)\n",
    "Y = np.array(Y)\n",
    "Y = Y.reshape(Y.shape[0],1)\n",
    "Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    min = np.min(X, axis=0)\n",
    "    max = np.max(X, axis=0)\n",
    "    X = (X - min) / (max - min)\n",
    "    return X\n",
    "X = normalize(X)\n",
    "Y = normalize(Y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4) (4, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,X.T .shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input layer shape  (4, 100)\n",
      "layer  1  weights shape  (4, 4)  biases shape  (4, 1)\n",
      "layer  2  weights shape  (2, 4)  biases shape  (2, 1)\n",
      "layer  3  weights shape  (1, 2)  biases shape  (1, 1)\n",
      "epoch  0  loss  0.6931471483024845  accuracy  30.685285169751552 % 30\n",
      "epoch  100  loss  0.6931456171749006  accuracy  30.685438282509935 % 1.1111111111111112\n",
      "epoch  200  loss  0.6931353823588324  accuracy  30.686461764116757 % 1.1111111111111112\n",
      "epoch  300  loss  0.6157621989409994  accuracy  38.423780105900065 % 1.1111111111111112\n",
      "epoch  400  loss  0.032495349468756325  accuracy  96.75046505312437 % 0.3703703703703704\n",
      "epoch  500  loss  0.01594398723154083  accuracy  98.40560127684593 % 0.3703703703703704\n",
      "epoch  600  loss  0.01045022161054227  accuracy  98.95497783894577 % 0.3703703703703704\n",
      "epoch  700  loss  0.007740527352994786  accuracy  99.22594726470052 % 0.3703703703703704\n",
      "epoch  800  loss  0.006134486821129296  accuracy  99.38655131788707 % 0.3703703703703704\n",
      "epoch  900  loss  0.005075238265996699  accuracy  99.49247617340033 % 0.3703703703703704\n",
      "epoch  1000  loss  0.004326220933923877  accuracy  99.56737790660762 % 0.3703703703703704\n",
      "epoch  1100  loss  0.0037686083838197556  accuracy  99.62313916161803 % 0.3703703703703704\n",
      "epoch  1200  loss  0.0033374910759747067  accuracy  99.66625089240253 % 0.3703703703703704\n",
      "epoch  1300  loss  0.0029947722836195304  accuracy  99.70052277163805 % 0.3703703703703704\n",
      "epoch  1400  loss  0.002715379888766992  accuracy  99.7284620111233 % 0.3703703703703704\n",
      "epoch  1500  loss  0.002483295295253608  accuracy  99.75167047047464 % 0.3703703703703704\n",
      "epoch  1600  loss  0.002287487044386074  accuracy  99.7712512955614 % 0.3703703703703704\n",
      "epoch  1700  loss  0.0021200868288519777  accuracy  99.7879913171148 % 0.3703703703703704\n",
      "epoch  1800  loss  0.001975351590653375  accuracy  99.80246484093466 % 0.3703703703703704\n",
      "epoch  1900  loss  0.001848972715447018  accuracy  99.8151027284553 % 0.3703703703703704\n",
      "epoch  2000  loss  0.0017376942152411107  accuracy  99.8262305784759 % 0.3703703703703704\n",
      "epoch  2100  loss  0.001638957522338147  accuracy  99.83610424776619 % 0.3703703703703704\n",
      "epoch  2200  loss  0.0015507608912173395  accuracy  99.84492391087826 % 0.3703703703703704\n",
      "epoch  2300  loss  0.001471510649258677  accuracy  99.85284893507414 % 0.3703703703703704\n",
      "epoch  2400  loss  0.0013999149443975106  accuracy  99.86000850556024 % 0.3703703703703704\n",
      "epoch  2500  loss  0.0013349183746756755  accuracy  99.86650816253243 % 0.3703703703703704\n",
      "epoch  2600  loss  0.0012756484292025506  accuracy  99.87243515707974 % 0.3703703703703704\n",
      "epoch  2700  loss  0.0012213863426489941  accuracy  99.8778613657351 % 0.3703703703703704\n",
      "epoch  2800  loss  0.0011715234301361362  accuracy  99.88284765698639 % 0.3703703703703704\n",
      "epoch  2900  loss  0.0011255464881041362  accuracy  99.88744535118958 % 0.3703703703703704\n",
      "epoch  3000  loss  0.0010830212671842866  accuracy  99.89169787328157 % 0.3703703703703704\n",
      "epoch  3100  loss  0.0010435706471317314  accuracy  99.89564293528682 % 0.3703703703703704\n",
      "epoch  3200  loss  0.0010068767660633283  accuracy  99.89931232339366 % 0.3703703703703704\n",
      "epoch  3300  loss  0.0009726611443275303  accuracy  99.90273388556726 % 0.3703703703703704\n",
      "epoch  3400  loss  0.0009406801251909505  accuracy  99.9059319874809 % 0.3703703703703704\n",
      "epoch  3500  loss  0.0009107223904583879  accuracy  99.90892776095416 % 0.3703703703703704\n",
      "epoch  3600  loss  0.0008826033029760599  accuracy  99.9117396697024 % 0.3703703703703704\n",
      "epoch  3700  loss  0.0008561580669276272  accuracy  99.91438419330724 % 0.3703703703703704\n",
      "epoch  3800  loss  0.0008312427496469679  accuracy  99.9168757250353 % 0.3703703703703704\n",
      "epoch  3900  loss  0.0008077285862774413  accuracy  99.91922714137226 % 0.3703703703703704\n",
      "epoch  4000  loss  0.0007855003317548952  accuracy  99.92144996682451 % 0.3703703703703704\n",
      "epoch  4100  loss  0.0007644554283154631  accuracy  99.92355445716845 % 0.3703703703703704\n",
      "epoch  4200  loss  0.000744503336653228  accuracy  99.92554966633467 % 0.3703703703703704\n",
      "epoch  4300  loss  0.0007255600837538194  accuracy  99.92744399162461 % 0.3703703703703704\n",
      "epoch  4400  loss  0.0007075514897433476  accuracy  99.92924485102567 % 0.3703703703703704\n",
      "epoch  4500  loss  0.0006904105863599015  accuracy  99.93095894136401 % 0.3703703703703704\n",
      "epoch  4600  loss  0.000674075919558846  accuracy  99.93259240804412 % 0.3703703703703704\n",
      "epoch  4700  loss  0.0006584922941296944  accuracy  99.93415077058702 % 0.3703703703703704\n",
      "epoch  4800  loss  0.0006436088437875014  accuracy  99.93563911562126 % 0.3703703703703704\n",
      "epoch  4900  loss  0.0006293803414354859  accuracy  99.93706196585646 % 0.3703703703703704\n",
      "epoch  5000  loss  0.0006157637483444217  accuracy  99.93842362516557 % 0.3703703703703704\n",
      "epoch  5100  loss  0.000602720869839407  accuracy  99.93972791301606 % 0.3703703703703704\n",
      "epoch  5200  loss  0.000590215962176393  accuracy  99.94097840378237 % 0.3703703703703704\n",
      "epoch  5300  loss  0.0005782169005054337  accuracy  99.94217830994945 % 0.3703703703703704\n",
      "epoch  5400  loss  0.0005666936260717171  accuracy  99.94333063739282 % 0.3703703703703704\n",
      "epoch  5500  loss  0.0005556182374575433  accuracy  99.94443817625425 % 0.3703703703703704\n",
      "epoch  5600  loss  0.0005449650783123148  accuracy  99.94550349216877 % 0.3703703703703704\n",
      "epoch  5700  loss  0.0005347109400359188  accuracy  99.94652890599642 % 0.3703703703703704\n",
      "epoch  5800  loss  0.000524833666508109  accuracy  99.94751663334918 % 0.3703703703703704\n",
      "epoch  5900  loss  0.000515312696930015  accuracy  99.948468730307 % 0.3703703703703704\n",
      "epoch  6000  loss  0.0005061293204258895  accuracy  99.9493870679574 % 0.3703703703703704\n",
      "epoch  6100  loss  0.0004972659454891969  accuracy  99.95027340545109 % 0.3703703703703704\n",
      "epoch  6200  loss  0.0004887061531081409  accuracy  99.95112938468918 % 0.3703703703703704\n",
      "epoch  6300  loss  0.00048043465415230656  accuracy  99.95195653458478 % 0.3703703703703704\n",
      "epoch  6400  loss  0.0004724369959295985  accuracy  99.95275630040705 % 0.3703703703703704\n",
      "epoch  6500  loss  0.00046470012117349915  accuracy  99.95352998788265 % 0.3703703703703704\n",
      "epoch  6600  loss  0.0004572112383187886  accuracy  99.95427887616812 % 0.3703703703703704\n",
      "epoch  6700  loss  0.00044995876478147955  accuracy  99.95500412352185 % 0.3703703703703704\n",
      "epoch  6800  loss  0.000442931697107536  accuracy  99.95570683028924 % 0.3703703703703704\n",
      "epoch  6900  loss  0.00043611971799629854  accuracy  99.95638802820037 % 0.3703703703703704\n",
      "epoch  7000  loss  0.000429513112038736  accuracy  99.95704868879612 % 0.3703703703703704\n",
      "epoch  7100  loss  0.0004231027566982582  accuracy  99.95768972433018 % 0.3703703703703704\n",
      "epoch  7200  loss  0.0004168800451698819  accuracy  99.958311995483 % 0.3703703703703704\n",
      "epoch  7300  loss  0.00041083678517579036  accuracy  99.95891632148242 % 0.3703703703703704\n",
      "epoch  7400  loss  0.0004049655222277366  accuracy  99.95950344777724 % 0.3703703703703704\n",
      "epoch  7500  loss  0.00039925885719800327  accuracy  99.96007411428019 % 0.3703703703703704\n",
      "epoch  7600  loss  0.00039371014037471003  accuracy  99.96062898596253 % 0.3703703703703704\n",
      "epoch  7700  loss  0.00038831276262490613  accuracy  99.96116872373752 % 0.3703703703703704\n",
      "epoch  7800  loss  0.0003830607005767101  accuracy  99.96169392994233 % 0.3703703703703704\n",
      "epoch  7900  loss  0.0003779481781953775  accuracy  99.96220518218047 % 0.3703703703703704\n",
      "epoch  8000  loss  0.00037296972047598856  accuracy  99.9627030279524 % 0.3703703703703704\n",
      "epoch  8100  loss  0.00036812012761491266  accuracy  99.96318798723851 % 0.3703703703703704\n",
      "epoch  8200  loss  0.0003633944745300356  accuracy  99.963660552547 % 0.3703703703703704\n",
      "epoch  8300  loss  0.0003587880746078444  accuracy  99.96412119253921 % 0.3703703703703704\n",
      "epoch  8400  loss  0.00035429648337459457  accuracy  99.96457035166254 % 0.3703703703703704\n",
      "epoch  8500  loss  0.00034991540868564605  accuracy  99.96500845913144 % 0.3703703703703704\n",
      "epoch  8600  loss  0.00034564094409948455  accuracy  99.96543590559006 % 0.3703703703703704\n",
      "epoch  8700  loss  0.0003414691531955121  accuracy  99.96585308468045 % 0.3703703703703704\n",
      "epoch  8800  loss  0.0003373964588643939  accuracy  99.96626035411356 % 0.3703703703703704\n",
      "epoch  8900  loss  0.0003334193159284403  accuracy  99.96665806840716 % 0.3703703703703704\n",
      "epoch  9000  loss  0.0003295344838677739  accuracy  99.96704655161322 % 0.3703703703703704\n",
      "epoch  9100  loss  0.00032573870400339676  accuracy  99.96742612959966 % 0.3703703703703704\n",
      "epoch  9200  loss  0.00032202900168639103  accuracy  99.96779709983136 % 0.3703703703703704\n",
      "epoch  9300  loss  0.0003184025251649389  accuracy  99.96815974748351 % 0.3703703703703704\n",
      "epoch  9400  loss  0.0003148564297769417  accuracy  99.96851435702231 % 0.3703703703703704\n",
      "epoch  9500  loss  0.0003113881192892573  accuracy  99.96886118807107 % 0.3703703703703704\n",
      "epoch  9600  loss  0.0003079950638823647  accuracy  99.96920049361177 % 0.3703703703703704\n",
      "epoch  9700  loss  0.0003046748465047045  accuracy  99.96953251534953 % 0.3703703703703704\n",
      "epoch  9800  loss  0.000301425152284746  accuracy  99.96985748477152 % 0.3703703703703704\n",
      "epoch  9900  loss  0.00029824375945501364  accuracy  99.9701756240545 % 0.3703703703703704\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "total_layers = 3\n",
    "neurons_in_layers = [4,2,1]\n",
    "input_dim = X.shape[1]\n",
    "epoches = 10000\n",
    "learning_rate = 30\n",
    "activation_function = ['Reliu','Reliu','Sigmoid']\n",
    "# Initialize weights and biases\n",
    "weights = {}\n",
    "bias = {}\n",
    "for i in range(total_layers):\n",
    "    if i == 0:\n",
    "        weights['layer_{}'.format(i+1)] = np.random.randn(neurons_in_layers[i],input_dim) * 0.01\n",
    "        bias['layer_{}'.format(i+1)] = np.zeros((neurons_in_layers[i],1))\n",
    "    else:\n",
    "        weights['layer_{}'.format(i+1)] = np.random.randn(neurons_in_layers[i],neurons_in_layers[i-1]) * 0.01\n",
    "        bias['layer_{}'.format(i+1)] = np.zeros((neurons_in_layers[i],1))\n",
    "\n",
    "# print shape of weights and biases for each layer\n",
    "print('input layer shape ',X.T.shape)\n",
    "for i in range(1,total_layers+1):\n",
    "    print('layer ',i,' weights shape ',weights['layer_{}'.format(i)].shape,' biases shape ',bias['layer_{}'.format(i)].shape)\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    # forward propagation\n",
    "    Z1 = np.dot(weights['layer_1'],X.T) + bias['layer_1']\n",
    "    A1 = np.maximum(0,Z1)\n",
    "    Z2 = np.dot(weights['layer_2'],A1) + bias['layer_2']\n",
    "    A2 = np.maximum(0,Z2)\n",
    "    Z3 = np.dot(weights['layer_3'],A2) + bias['layer_3']\n",
    "    A3 = 1/(1+np.exp(-Z3))\n",
    "\n",
    "    # loss function\n",
    "    loss = (-1/X.shape[0]) * np.sum(Y.T * np.log(A3) + (1-Y.T) * np.log(1-A3))\n",
    "    # back propagation\n",
    "    dZ3 = A3 - Y.T\n",
    "    dW3 = (1/X.shape[0]) * np.dot(dZ3,A2.T)\n",
    "    db3 = (1/X.shape[0]) * np.sum(dZ3,axis=1,keepdims=True)\n",
    "    dZ2 = np.dot(weights['layer_3'].T,dZ3) * (A2 > 0)\n",
    "    dW2 = (1/X.shape[0]) * np.dot(dZ2,A1.T)\n",
    "    db2 = (1/X.shape[0]) * np.sum(dZ2,axis=1,keepdims=True)\n",
    "    dZ1 = np.dot(weights['layer_2'].T,dZ2) * (A1 > 0)\n",
    "    dW1 = (1/X.shape[0]) * np.dot(dZ1,X)\n",
    "    db1 = (1/X.shape[0]) * np.sum(dZ1,axis=1,keepdims=True)\n",
    "\n",
    "    # update weights and biases\n",
    "    weights['layer_3'] = weights['layer_3'] - learning_rate * dW3\n",
    "    bias['layer_3'] = bias['layer_3'] - learning_rate * db3\n",
    "    weights['layer_2'] = weights['layer_2'] - learning_rate * dW2\n",
    "    bias['layer_2'] = bias['layer_2'] - learning_rate * db2\n",
    "    weights['layer_1'] = weights['layer_1'] - learning_rate * dW1\n",
    "    bias['layer_1'] = bias['layer_1'] - learning_rate * db1\n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch ',epoch,' loss ',loss,' accuracy ',(1-loss)*100,'%',learning_rate)\n",
    "    if epoch == 0:\n",
    "        previos_loss = loss\n",
    "    else:\n",
    "        if loss > previos_loss:\n",
    "            learning_rate = learning_rate/3\n",
    "        previos_loss = loss\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
